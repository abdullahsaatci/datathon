{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90279,"databundleVersionId":10477255,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport random\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change to the desired directory\nos.chdir('/kaggle/input/datathon-ai-qualification-round')\n\n# Verify the current directory\nprint(os.getcwd())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specify the folder path\nfolder_path = \"/kaggle/working/new_dataset\"\n\ntry:\n    shutil.rmtree(folder_path)\n    print(f\"Folder '{folder_path}' and its contents have been removed.\")\nexcept FileNotFoundError:\n    print(f\"Folder '{folder_path}' does not exist.\")\nexcept Exception as e:\n    print(f\"Error removing folder: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define paths for the original dataset and the new dataset\noriginal_dataset_path = \"train/train\"\nnew_dataset_path = \"/kaggle/working/new_dataset\"\ncsv_file_path = \"train_data.csv\"\n\n# Load the CSV file\ntrain_data = pd.read_csv(csv_file_path)\n\n# Categories to split into\ncategories = train_data[\"city\"].unique()\n\n# Create subdirectories for train, valid, and test in the new structure\nfor split in [\"train\", \"valid\", \"test\"]:\n    for category in categories:\n        os.makedirs(os.path.join(new_dataset_path, split, category), exist_ok=True)\n\n# Function to split dataset\ndef split_dataset(data, train_ratio=0.79, valid_ratio=0.2, test_ratio=0.01):\n    grouped = data.groupby(\"city\")\n\n    for category, group in grouped:\n        images = group[\"filename\"].tolist()\n        random.shuffle(images)\n\n        train_count = int(len(images) * train_ratio)\n        valid_count = int(len(images) * valid_ratio)\n        print(len(images))\n\n        train_images = images[:train_count]\n        valid_images = images[train_count:train_count + valid_count]\n        test_images = images[train_count + valid_count:]\n        print(len(train_images))\n        print(len(valid_images))\n        print(len(test_images))\n\n        # Move images to the new dataset structure\n        for image in train_images:\n            src = os.path.join(original_dataset_path, image)\n            dest = os.path.join(new_dataset_path, \"train\", category, image)\n            if os.path.exists(src):\n                shutil.copy(src, dest)\n\n        for image in valid_images:\n            src = os.path.join(original_dataset_path, image)\n            dest = os.path.join(new_dataset_path, \"valid\", category, image)\n            if os.path.exists(src):\n                shutil.copy(src, dest)\n\n        for image in test_images:\n            src = os.path.join(original_dataset_path, image)\n            dest = os.path.join(new_dataset_path, \"test\", category, image)\n            if os.path.exists(src):\n                shutil.copy(src, dest)\n\n# Perform the split\nsplit_dataset(train_data)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specify the folder path\nfolder_path = \"/kaggle/working/new_dataset/test/Ankara\"\n\n# Count the number of files in the folder\nfile_count = sum([len(files) for _, _, files in os.walk(folder_path)])\n\nprint(f\"The number of files in the folder '{folder_path}' is: {file_count}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change to the desired directory\nos.chdir('/kaggle/working/new_dataset')\n\n# Verify the current directory\nprint(os.getcwd())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specify the current and new folder paths\ncurrent_folder = \"/kaggle/working/new_dataset/valid\"\nnew_folder = \"/kaggle/working/new_dataset/val\"\n\n# Rename the folder\nif os.path.exists(current_folder):\n    os.rename(current_folder, new_folder)\n    print(f\"Renamed folder '{current_folder}' to '{new_folder}'\")\nelse:\n    print(f\"Folder '{current_folder}' does not exist\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO(\"yolo11x-cls.yaml\")  # build a new model from YAML\nmodel = YOLO(\"yolo11x-cls.pt\")  # load a pretrained model (recommended for training)\nmodel = YOLO(\"yolo11x-cls.yaml\").load(\"yolo11x-cls.pt\")  # build from YAML and transfer weights\n\n# Train the model\nresults = model.train(data=\"\", epochs=150, imgsz=640)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport numpy as np\n\n# Load the trained model\nmodel = YOLO(\"/kaggle/working/new_dataset/runs/classify/train/weights/best.pt\")\n\n# Path to the test dataset\ntest_path = \"/kaggle/working/new_dataset/val\" \n\n# Map class names to indices\nclass_names = [\"Ankara\", \"Istanbul\", \"Izmir\"]\nclass_to_idx = {name: i for i, name in enumerate(class_names)}\n\n# Lists to store ground truth and predictions\ny_true = []\ny_pred = []\n\n# Iterate through each folder (class) in the test dataset\nfor class_name in os.listdir(test_path):\n    class_folder = os.path.join(test_path, class_name)\n    if os.path.isdir(class_folder):\n        for image_name in os.listdir(class_folder):\n            image_path = os.path.join(class_folder, image_name)\n            \n            # Predict the class of the image\n            result = model.predict(source=image_path, imgsz=640, save=False, conf=0.25)\n            \n            # Extract predicted probabilities and class\n            probs = result[0].probs.data.cpu().numpy()  # Extract probabilities as a NumPy array\n            predicted_class = np.argmax(probs)  # Get the predicted class index\n            \n            # Append ground truth and prediction\n            y_true.append(class_to_idx[class_name])  # True label\n            y_pred.append(predicted_class)          # Predicted label\n\n# Calculate accuracy\naccuracy = accuracy_score(y_true, y_pred)\n\n# Calculate F1 score (macro-average for multiple classes)\nf1 = f1_score(y_true, y_pred, average=\"macro\")\n\n# Print a detailed classification report\nreport = classification_report(y_true, y_pred, target_names=class_names)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score (Macro): {f1:.4f}\")\nprint(\"\\nClassification Report:\\n\", report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the trained model\nmodel = YOLO(\"/kaggle/working/new_dataset/runs/classify/train/weights/best.pt\")\n\n# Load the test.csv file\ncsv_file_path = \"/kaggle/input/datathon-ai-qualification-round/test.csv\"\ntest_df = pd.read_csv(csv_file_path)\n\n# Path to the test images folder\ntest_images_folder = \"/kaggle/input/datathon-ai-qualification-round/test/test\"\n\n# Define the class names as per your model's training\nclass_names = [\"Ankara\", \"Istanbul\", \"Izmir\"]\n\n# Iterate through each row in the CSV to predict the city\nfor index, row in test_df.iterrows():\n    image_path = os.path.join(test_images_folder, row['filename'])\n    # Predict the class of the image\n    result = model.predict(source=image_path, imgsz=640, save=False, conf=0.25)\n    # Get the predicted class index and corresponding city name\n    probs = result[0].probs.data.cpu().numpy()  # Extract probabilities as a NumPy array\n    predicted_class = class_names[np.argmax(probs)]  # Map index to class name\n    # Update the city column with the predicted city name\n    test_df.at[index, 'city'] = predicted_class\n\n# Save the updated DataFrame back to a CSV file\noutput_csv_path = \"/kaggle/working/submission.csv\"\ntest_df.to_csv(output_csv_path, index=False)\n\nprint(f\"Predictions saved to {output_csv_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}